{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45593743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-win_amd64.whl (38.6 MB)\n",
      "     ---------------------------------------- 38.6/38.6 MB 7.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\anaconda\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf96c1c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def preprocess_data(json_files, img_directory):  # 이미지 디렉토리 경로를 인자로 추가\n",
    "    # 이미지 데이터와 레이블을 저장할 리스트 선언\n",
    "    images = []\n",
    "    labels = []\n",
    "    # 모든 JSON 파일에 대해 처리\n",
    "    for json_file in json_files:\n",
    "        # JSON 파일 불러오기\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # 이미지 경로 생성\n",
    "        img_file = data['imagePath']  # JSON 파일에 기록된 이미지 파일명\n",
    "        img_path = os.path.join(img_directory, img_file)  # 이미지 파일의 절대 경로 생성\n",
    "        \n",
    "        # 이미지 불러오기\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # JSON 파일의 폴리곤 좌표를 이용해 이미지에 다각형 그리기\n",
    "        for shape in data['shapes']:\n",
    "            if shape['label'] == 'tom_flower_poly':\n",
    "                points = np.array(shape['points'], np.int32)\n",
    "                cv2.fillPoly(img, [points], (255, 255, 255))\n",
    "\n",
    "        # 이미지 데이터와 레이블 저장\n",
    "        images.append(img)\n",
    "        labels.append(1 if len([shape for shape in data['shapes'] if shape['label'] == 'tom_flower_poly']) >= 3 else 0)\n",
    "    \n",
    "    # 리스트를 numpy array로 변환\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels\n",
    "\n",
    "# 딥러닝 모델 생성 함수\n",
    "def create_model():\n",
    "    # Sequential 모델 생성\n",
    "    model = Sequential()\n",
    "    # 첫 번째 Convolutional layer 추가. 입력 이미지의 크기는 1920x1080, 채널은 3(RGB)\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(1920, 1080, 3)))\n",
    "    # MaxPooling layer 추가\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # 두 번째 Convolutional layer 추가\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    # MaxPooling layer 추가\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # Flatten layer 추가. 이것을 통해 이전 Layer의 2차원 데이터를 1차원으로 만들어줍니다.\n",
    "    model.add(Flatten())\n",
    "    # 첫 번째 Fully connected layer(Dense) 추가\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    # 출력 레이어 추가. 이진 분류 문제이므로 노드 수는 1, 활성화 함수는 sigmoid\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # 모델 컴파일. Optimizer는 Adam, Loss function은 Binary Crossentropy 사용\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c9ca805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def preprocess_data(json_files, img_directory):  \n",
    "    images = []\n",
    "    labels = []\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        img_file = data['imagePath']\n",
    "        img_path = os.path.join(img_directory, img_file)\n",
    "        \n",
    "        img = Image.open(img_path)\n",
    "        img = np.array(img)\n",
    "        \n",
    "        if img is None:\n",
    "            print(f\"이미지 로드 실패: {img_path}\")\n",
    "            continue  \n",
    "\n",
    "        for shape in data['shapes']:\n",
    "            if shape['label'] == 'tom_flower_poly':\n",
    "                points = np.array(shape['points'], np.int32)\n",
    "                cv2.fillPoly(img, [points], (255, 255, 255))\n",
    "\n",
    "        images.append(img)\n",
    "        labels.append(1 if len([shape for shape in data['shapes'] if shape['label'] == 'tom_flower_poly']) >= 3 else 0)\n",
    "    \n",
    "    print(f\"로드된 이미지 수: {len(images)}\")\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    return images, labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e55f662",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 5.93 MiB for an array with shape (1080, 1920, 3) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m json_files \u001b[38;5;241m=\u001b[39m json_files[:\u001b[38;5;241m200\u001b[39m]\n\u001b[0;32m     18\u001b[0m img_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/tomato_label/097.지능형_스마트팜_통합_데이터(토마토)/01.데이터/1.Training/원천데이터/f.만개꽃/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 20\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m train_images, test_images, train_labels, test_labels \u001b[38;5;241m=\u001b[39m train_test_split(images, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model()\n",
      "Cell \u001b[1;32mIn[28], line 24\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(json_files, img_directory)\u001b[0m\n\u001b[0;32m     21\u001b[0m img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(img_directory, img_file)\n\u001b[0;32m     23\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\n\u001b[1;32m---> 24\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m이미지 로드 실패: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 5.93 MiB for an array with shape (1080, 1920, 3) and data type uint8"
     ]
    }
   ],
   "source": [
    "# 딥러닝 모델 생성 함수\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(1920, 1080, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "directory = 'E:/tomato_label/097.지능형_스마트팜_통합_데이터(토마토)/01.데이터/1.Training/라벨링데이터/f.만개꽃/'\n",
    "json_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.json')]\n",
    "json_files = json_files[:200]\n",
    "\n",
    "img_directory = u'E:/tomato_label/097.지능형_스마트팜_통합_데이터(토마토)/01.데이터/1.Training/원천데이터/f.만개꽃/'\n",
    "\n",
    "images, labels = preprocess_data(json_files, img_directory)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "model = create_model()\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29f05bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터 전처리 함수\n",
    "def preprocess_data(json_file, img_directory):  \n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    img_file = data['imagePath']\n",
    "    img_path = os.path.join(img_directory, img_file)\n",
    "        \n",
    "    img = Image.open(img_path)\n",
    "    img = np.array(img)\n",
    "        \n",
    "    if img is None:\n",
    "        print(f\"이미지 로드 실패: {img_path}\")\n",
    "        return None, None\n",
    "\n",
    "    for shape in data['shapes']:\n",
    "        if shape['label'] == 'tom_flower_poly':\n",
    "            points = np.array(shape['points'], np.int32)\n",
    "            cv2.fillPoly(img, [points], (255, 255, 255))\n",
    "\n",
    "    label = 1 if len([shape for shape in data['shapes'] if shape['label'] == 'tom_flower_poly']) >= 3 else 0\n",
    "    return img, label\n",
    "\n",
    "# 데이터 로드 함수\n",
    "def data_generator(json_files, img_directory, batch_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for json_file in json_files:\n",
    "        img, label = preprocess_data(json_file, img_directory)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "            if len(images) == batch_size:\n",
    "                yield np.array(images), np.array(labels)\n",
    "                images = []\n",
    "                labels = []\n",
    "\n",
    "# 딥러닝 모델 생성 함수\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(1920, 1080, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "725b82d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[8198656,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:StatelessRandomUniformV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 9\u001b[0m\n\u001b[0;32m      5\u001b[0m img_directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/tomato_label/097.지능형_스마트팜_통합_데이터(토마토)/01.데이터/1.Training/원천데이터/f.만개꽃/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      7\u001b[0m train_json_files, test_json_files \u001b[38;5;241m=\u001b[39m train_test_split(json_files, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m  \u001b[38;5;66;03m# 원하는 배치 크기를 지정\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 훈련 데이터셋에 대해 모델 학습\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[30], line 50\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)))\n\u001b[0;32m     49\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Flatten())\n\u001b[1;32m---> 50\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     52\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\src\\backend.py:2100\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[1;34m(self, shape, minval, maxval, dtype, nonce)\u001b[0m\n\u001b[0;32m   2098\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nonce:\n\u001b[0;32m   2099\u001b[0m         seed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[1;32m-> 2100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\n\u001b[0;32m   2108\u001b[0m     shape\u001b[38;5;241m=\u001b[39mshape,\n\u001b[0;32m   2109\u001b[0m     minval\u001b[38;5;241m=\u001b[39mminval,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2112\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_legacy_seed(),\n\u001b[0;32m   2113\u001b[0m )\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__StatelessRandomUniformV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} OOM when allocating tensor with shape[8198656,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:StatelessRandomUniformV2] name: "
     ]
    }
   ],
   "source": [
    "directory = 'E:/tomato_label/097.지능형_스마트팜_통합_데이터(토마토)/01.데이터/1.Training/라벨링데이터/f.만개꽃/'\n",
    "json_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.json')]\n",
    "json_files = json_files[:200]\n",
    "\n",
    "img_directory = u'E:/tomato_label/097.지능형_스마트팜_통합_데이터(토마토)/01.데이터/1.Training/원천데이터/f.만개꽃/'\n",
    "\n",
    "train_json_files, test_json_files = train_test_split(json_files, test_size=0.2, random_state=42)\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 4  # 원하는 배치 크기를 지정\n",
    "\n",
    "# 훈련 데이터셋에 대해 모델 학습\n",
    "for imgs, labels in data_generator(train_json_files, img_directory, BATCH_SIZE):\n",
    "    model.train_on_batch(imgs, labels)\n",
    "\n",
    "# 테스트 데이터셋에 대해 모델 평가\n",
    "eval_loss, eval_acc = 0, 0\n",
    "n_test_samples = 0\n",
    "for imgs, labels in data_generator(test_json_files, img_directory, BATCH_SIZE):\n",
    "    loss, acc = model.evaluate(imgs, labels, verbose=0)\n",
    "    eval_loss += loss * len(labels)\n",
    "    eval_acc += acc * len(labels)\n",
    "    n_test_samples += len(labels)\n",
    "\n",
    "print(f\"테스트 손실: {eval_loss / n_test_samples}\")\n",
    "print(f\"테스트 정확도: {eval_acc / n_test_samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f52dde5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data_generator() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m  \u001b[38;5;66;03m# 원하는 배치 크기를 지정\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 훈련 데이터셋에 대해 모델 학습\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgs, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_json_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain_on_batch(imgs, labels)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 테스트 데이터셋에 대해 모델 평가\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: data_generator() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "directory = 'E:/tomato_label/097.지능형_스마트팜_통합_데이터(토마토)/01.데이터/1.Training/라벨링데이터/f.만개꽃/'\n",
    "json_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.json')]\n",
    "json_files = json_files[:200]\n",
    "\n",
    "img_directory = u'E:/tomato_label/097.지능형_스마트팜_통합_데이터(토마토)/01.데이터/1.Training/원천데이터/f.만개꽃/'\n",
    "\n",
    "train_json_files, test_json_files = train_test_split(json_files, test_size=0.2, random_state=42)\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "# 훈련 데이터셋에 대해 모델 학습\n",
    "for img, label in data_generator(train_json_files, img_directory):\n",
    "    img = img.reshape(-1, 1920, 1080, 3)  # 이미지 차원 변경\n",
    "    #img = np.expand_dims(img, axis=0)\n",
    "    label = np.array([label])\n",
    "    model.train_on_batch(img, label)\n",
    "\n",
    "# 테스트 데이터셋에 대해 모델 평가\n",
    "eval_loss, eval_acc = 0, 0\n",
    "n_test_samples = 0\n",
    "for img, label in data_generator(test_json_files, img_directory):\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    label = np.array([label])\n",
    "    loss, acc = model.evaluate(img, label, verbose=0)\n",
    "    eval_loss += loss\n",
    "    eval_acc += acc\n",
    "    n_test_samples += 1\n",
    "\n",
    "print(f\"테스트 손실: {eval_loss / n_test_samples}\")\n",
    "print(f\"테스트 정확도: {eval_acc / n_test_samples}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
